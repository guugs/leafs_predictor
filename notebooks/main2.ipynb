{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import brier_score_loss, roc_auc_score\n",
    "\n",
    "TEAM = \"TOR\"\n",
    "\n",
    "NAME_TO_ABBR = {\n",
    "    \"Anaheim Ducks\": \"ANA\",\"Arizona Coyotes\": \"ARI\",\"Boston Bruins\": \"BOS\",\"Buffalo Sabres\": \"BUF\",\n",
    "    \"Calgary Flames\": \"CGY\",\"Carolina Hurricanes\": \"CAR\",\"Chicago Blackhawks\": \"CHI\",\"Colorado Avalanche\": \"COL\",\n",
    "    \"Columbus Blue Jackets\": \"CBJ\",\"Dallas Stars\": \"DAL\",\"Detroit Red Wings\": \"DET\",\"Edmonton Oilers\": \"EDM\",\n",
    "    \"Florida Panthers\": \"FLA\",\"Los Angeles Kings\": \"LAK\",\"Minnesota Wild\": \"MIN\",\"Montreal Canadiens\": \"MTL\",\n",
    "    \"Nashville Predators\": \"NSH\",\"New Jersey Devils\": \"NJD\",\"New York Islanders\": \"NYI\",\"New York Rangers\": \"NYR\",\n",
    "    \"Ottawa Senators\": \"OTT\",\"Philadelphia Flyers\": \"PHI\",\"Pittsburgh Penguins\": \"PIT\",\"San Jose Sharks\": \"SJS\",\n",
    "    \"Seattle Kraken\": \"SEA\",\"St. Louis Blues\": \"STL\",\"Tampa Bay Lightning\": \"TBL\",\"Toronto Maple Leafs\": \"TOR\",\n",
    "    \"Utah Hockey Club\": \"UTA\",\"Vancouver Canucks\": \"VAN\",\"Vegas Golden Knights\": \"VGK\",\"Washington Capitals\": \"WSH\",\n",
    "    \"Winnipeg Jets\": \"WPG\"\n",
    "}\n",
    "SCHEDULE_CSV = \"../data/raw/schedule.csv\"\n",
    "TEAMS_CSV = \"../data/raw/teams.csv\"\n",
    "SAVE_PCT_CSV = \"../data/clean/team_save_percentages.csv\"\n",
    "BACKTEST_CSV = \"../data/raw/backtest.csv\"\n",
    "\n",
    "HOME_EDGE = 5.0           # Elo pts for home ice\n",
    "B2B_PENALTY = 10.0        # Elo pts penalty for back-to-back\n",
    "REST_PTS_PER_DAY = 3.0    # Elo pts per rest_diff day\n",
    "ELO_SCALE_DEN = 600.0     # larger => flatter probabilities\n",
    "ALPHA_ELO = 0.65          # 1.0 => pure Elo, 0.0 => coin flip\n",
    "\n",
    "def elo_prob_row(row: pd.Series) -> float:\n",
    "    \"\"\"Deterministic win probability from Elo + simple context tweaks.\"\"\"\n",
    "    diff = float(row[\"elo_for\"]) - float(row[\"elo_against\"])\n",
    "    if int(row[\"home\"]) == 1:\n",
    "        diff += HOME_EDGE\n",
    "    if int(row[\"back_to_back\"]) == 1:\n",
    "        diff -= B2B_PENALTY\n",
    "    diff += REST_PTS_PER_DAY * float(row.get(\"rest_diff\", 0))\n",
    "    p_elo = 1.0 / (1.0 + 10.0 ** (-(diff) / ELO_SCALE_DEN))\n",
    "    return float(ALPHA_ELO * p_elo + (1.0 - ALPHA_ELO) * 0.5)\n",
    "\n",
    "def allocate_otl(loss_idx: np.ndarray, probs: np.ndarray, expected_share: float) -> set:\n",
    "    \"\"\"\n",
    "    Mark a subset of predicted losses as OTL to match an expected share.\n",
    "    Picks the losses whose probs are closest to 0.5.\n",
    "    \"\"\"\n",
    "    n = len(loss_idx)\n",
    "    k = int(round(max(0.0, min(1.0, expected_share)) * n))\n",
    "    if n == 0 or k == 0:\n",
    "        return set()\n",
    "    closeness = np.abs(probs[loss_idx] - 0.5)\n",
    "    otl_pick = loss_idx[np.argsort(closeness)[:k]]\n",
    "    return set(otl_pick)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load shed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_leafs_schedule_from_csv(\n",
    "    csv_path: str,\n",
    "    team_abbr: str = TEAM,\n",
    "    date_col: str = \"Date\",\n",
    "    home_col: str = \"Home Team\",\n",
    "    away_col: str = \"Away Team\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load a FixtureDownload-style Leafs schedule and return:\n",
    "      date (datetime64[ns]), home_team, away_team, opponent, home,\n",
    "      back_to_back, rest_days, rest_diff (placeholder=0),\n",
    "      plus passthrough columns if present: Location, Result, Match Number, Round Number.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Normalize column names we need\n",
    "    for col in (date_col, home_col, away_col):\n",
    "        if col not in df.columns:\n",
    "            raise KeyError(f\"Expected column '{col}' not found. Got: {list(df.columns)}\")\n",
    "    df = df.rename(columns={date_col: \"date\", home_col: \"home_team\", away_col: \"away_team\"})\n",
    "\n",
    "    keep = [\"date\", \"home_team\", \"away_team\"]\n",
    "    for opt in [\"Location\", \"Result\", \"Match Number\", \"Round Number\"]:\n",
    "        if opt in df.columns:\n",
    "            keep.append(opt)\n",
    "    df = df[keep].copy()\n",
    "\n",
    "    date_str = df[\"date\"].astype(str).str.strip()\n",
    "    parsed = pd.to_datetime(date_str, format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "    na = parsed.isna()\n",
    "    if na.any():  \n",
    "        parsed.loc[na] = pd.to_datetime(date_str[na], errors=\"coerce\")\n",
    "    df[\"date\"] = parsed\n",
    "\n",
    "    df[\"home\"] = (df[\"home_team\"] == team_abbr).astype(int)\n",
    "    df[\"opponent\"] = np.where(df[\"home\"] == 1, df[\"away_team\"], df[\"home_team\"])\n",
    "\n",
    "    df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "    d_days = df[\"date\"].diff().dt.days.fillna(2).clip(lower=0).astype(int)\n",
    "    df[\"rest_days\"] = d_days\n",
    "    df[\"back_to_back\"] = (d_days == 1).astype(int)\n",
    "\n",
    "    df[\"rest_diff\"] = 0\n",
    "\n",
    "    order = [\"date\",\"home_team\",\"away_team\",\"opponent\",\"home\",\"back_to_back\",\"rest_days\",\"rest_diff\"]\n",
    "    for opt in [\"Location\", \"Result\", \"Match Number\", \"Round Number\"]:\n",
    "        if opt in df.columns:\n",
    "            order.append(opt)\n",
    "    return df[order]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "elo mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_elo_map(\n",
    "    teams_csv: str = \"../data/raw/teams.csv\",\n",
    "    save_pct_csv: str = \"../data/clean/team_save_percentages.csv\",\n",
    ") -> tuple[dict, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Build a composite strength metric (EV/PP/PK + Save%) and map to Elo.\n",
    "    Returns (elo_map: dict[abbr->elo], comp_df).\n",
    "    \"\"\"\n",
    "    teams_df = pd.read_csv(teams_csv).copy()\n",
    "    teams_df[\"season\"] = pd.to_numeric(teams_df[\"season\"], errors=\"coerce\")\n",
    "    latest_season = int(teams_df[\"season\"].max())\n",
    "\n",
    "    t = teams_df.loc[teams_df[\"season\"] == latest_season, [\"team\",\"situation\",\"iceTime\",\"xGoalsFor\",\"xGoalsAgainst\"]].copy()\n",
    "    SIT_MAP = {\"5on5\":\"EV\", \"5on4\":\"PP\", \"4on5\":\"PK\"}\n",
    "    t[\"SIT\"] = t[\"situation\"].map(SIT_MAP)\n",
    "\n",
    "   #multiply rates by 60\n",
    "    t[\"iceTime\"] = pd.to_numeric(t[\"iceTime\"], errors=\"coerce\").replace(0, np.nan)\n",
    "    t[\"xGoalsFor\"] = pd.to_numeric(t[\"xGoalsFor\"], errors=\"coerce\")\n",
    "    t[\"xGoalsAgainst\"] = pd.to_numeric(t[\"xGoalsAgainst\"], errors=\"coerce\")\n",
    "    t[\"xGF60\"] = (t[\"xGoalsFor\"] / t[\"iceTime\"]) * 60.0\n",
    "    t[\"xGA60\"] = (t[\"xGoalsAgainst\"] / t[\"iceTime\"]) * 60.0\n",
    "    t[\"net_xG60\"] = t[\"xGF60\"] - t[\"xGA60\"]\n",
    "\n",
    "    pp = t.loc[t[\"SIT\"]==\"PP\"].groupby(\"team\", as_index=False)[[\"xGF60\"]].mean()\n",
    "    pk = t.loc[t[\"SIT\"]==\"PK\"].groupby(\"team\", as_index=False)[[\"xGA60\"]].mean()\n",
    "    ev = t.loc[t[\"SIT\"]==\"EV\"].groupby(\"team\", as_index=False)[[\"net_xG60\"]].mean()\n",
    "\n",
    "    # Fill with default values\n",
    "    all_teams = pd.DataFrame({\"team\": t[\"team\"].dropna().unique()})\n",
    "    pp = all_teams.merge(pp, on=\"team\", how=\"left\");  pp[\"xGF60\"] = pp[\"xGF60\"].fillna(pp[\"xGF60\"].mean())\n",
    "    pk = all_teams.merge(pk, on=\"team\", how=\"left\");  pk[\"xGA60\"] = pk[\"xGA60\"].fillna(pk[\"xGA60\"].mean())\n",
    "    ev = all_teams.merge(ev, on=\"team\", how=\"left\");  ev[\"net_xG60\"] = ev[\"net_xG60\"].fillna(ev[\"net_xG60\"].mean())\n",
    "\n",
    "    #zscores\n",
    "    def z(s: pd.Series) -> pd.Series:\n",
    "        s = s.astype(float)\n",
    "        mu = s.mean()\n",
    "        sd = s.std(ddof=0)\n",
    "        return (s - mu) / (sd if sd != 0 else 1.0)\n",
    "\n",
    "    ev_z = z(ev[\"net_xG60\"])            # higher better\n",
    "    pp_z = z(pp[\"xGF60\"])               # higher better\n",
    "    # PK: lower xGA60 is better -> invert before z\n",
    "    pk_z = z(-pk[\"xGA60\"])\n",
    "\n",
    "    # Goalie save % (map full names -> abbr to match others)\n",
    "    sv_df = pd.read_csv(save_pct_csv).rename(columns={\"team\":\"team_name\",\"savePct\":\"savePct\"})\n",
    "    sv_df[\"team\"] = sv_df[\"team_name\"].map(NAME_TO_ABBR)\n",
    "    sv = all_teams.merge(sv_df[[\"team\",\"savePct\"]], on=\"team\", how=\"left\")\n",
    "    sv[\"savePct\"] = pd.to_numeric(sv[\"savePct\"], errors=\"coerce\")\n",
    "    sv[\"savePct\"] = sv[\"savePct\"].fillna(sv[\"savePct\"].mean())\n",
    "    sv_z = z(sv[\"savePct\"])\n",
    "\n",
    "    W_EV, W_PP, W_PK, W_SV = 0.60, 0.20, 0.15, 0.05\n",
    "    comp = all_teams.copy()\n",
    "    comp[\"ev_z\"] = ev_z.values\n",
    "    comp[\"pp_z\"] = pp_z.values\n",
    "    comp[\"pk_z\"] = pk_z.values\n",
    "    comp[\"sv_z\"] = sv_z.values\n",
    "    comp[\"z_composite\"] = W_EV*comp[\"ev_z\"] + W_PP*comp[\"pp_z\"] + W_PK*comp[\"pk_z\"] + W_SV*comp[\"sv_z\"]\n",
    "    comp[\"elo\"] = 1500.0 + 100.0 * comp[\"z_composite\"]\n",
    "\n",
    "    elo_map = dict(zip(comp[\"team\"], comp[\"elo\"]))\n",
    "    return elo_map, comp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def _norm_name(s: str) -> str:\n",
    "    s = str(s or \"\")\n",
    "    s = re.sub(r\"[^a-zA-Z\\s\\-.']\", \"\", s).lower().strip()\n",
    "    return re.sub(r\"\\s+\", \" \", s)\n",
    "\n",
    "def compute_offseason_bump_for_team(\n",
    "    transactions_csv: str,\n",
    "    skaters_csv: str,\n",
    "    team_abbr: str = \"TOR\",\n",
    "    elo_per_std: float = 60.0,\n",
    "    min_gp: int = 10,\n",
    ") -> tuple[int, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Uses your schema:\n",
    "      - transactions.csv: ['player','team_from','team_to']\n",
    "      - skaters.csv: ['name','season','situation','gameScore','games_played', ...]\n",
    "    Builds GS/GP from skaters (latest season, situation == 'all'), then\n",
    "    sums (+1 for acquisitions, -1 for departures) * GS/GP, scaled by league std.\n",
    "    Returns (elo_bump_int, details_df).\n",
    "    \"\"\"\n",
    "    tx = pd.read_csv(transactions_csv).copy()\n",
    "    sk = pd.read_csv(skaters_csv).copy()\n",
    "\n",
    "    # Normalize player names for robust joins\n",
    "    tx[\"_player_norm\"] = tx[\"player\"].map(_norm_name)\n",
    "    sk[\"_player_norm\"] = sk[\"name\"].map(_norm_name)\n",
    "\n",
    "    # Latest season\n",
    "    if \"season\" in sk.columns:\n",
    "        sk[\"season\"] = pd.to_numeric(sk[\"season\"], errors=\"coerce\")\n",
    "        sk = sk.loc[sk[\"season\"] == sk[\"season\"].max()].copy()\n",
    "\n",
    "    # Prefer 'all' situation if present\n",
    "    if \"situation\" in sk.columns:\n",
    "        sk_all = sk.loc[sk[\"situation\"].astype(str).str.lower() == \"all\"]\n",
    "        if not sk_all.empty:\n",
    "            sk = sk_all\n",
    "\n",
    "    # Build GS/GP\n",
    "    gs = pd.to_numeric(sk.get(\"gameScore\"), errors=\"coerce\").fillna(0.0)\n",
    "    gp = pd.to_numeric(sk.get(\"games_played\"), errors=\"coerce\").fillna(0.0)\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        gs_per_gp = np.where(gp > 0, gs / gp, 0.0)\n",
    "    sk[\"gs_per_gp\"] = gs_per_gp\n",
    "\n",
    "    # Optional minimum GP filter\n",
    "    if \"games_played\" in sk.columns:\n",
    "        sk = sk.loc[pd.to_numeric(sk[\"games_played\"], errors=\"coerce\").fillna(0) >= min_gp].copy()\n",
    "\n",
    "    # League std (scaling)\n",
    "    std = float(pd.Series(sk[\"gs_per_gp\"]).std(ddof=0)) or 1.0\n",
    "\n",
    "    # Merge onto transactions\n",
    "    m = tx.merge(sk[[\"_player_norm\",\"gs_per_gp\"]], on=\"_player_norm\", how=\"left\")\n",
    "\n",
    "    # Direction: acquired (+1) if team_to == TOR; departed (−1) if team_from == TOR\n",
    "    sign = np.where(m[\"team_to\"] == team_abbr, +1,\n",
    "            np.where(m[\"team_from\"] == team_abbr, -1, 0))\n",
    "    m[\"_sign\"] = sign\n",
    "\n",
    "    stat_vals = pd.to_numeric(m[\"gs_per_gp\"], errors=\"coerce\").fillna(0.0)\n",
    "    contribution = sign * stat_vals\n",
    "    m = m.assign(gs_per_gp=stat_vals, contribution=contribution)\n",
    "\n",
    "    # Convert to Elo bump\n",
    "    elo_bump = elo_per_std * (contribution.sum() / std)\n",
    "    return int(round(elo_bump)), m[[\"player\",\"team_from\",\"team_to\",\"gs_per_gp\",\"contribution\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attach to sched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_elo_to_schedule(schedule_df: pd.DataFrame, elo_map: dict, team_abbr: str = TEAM) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Normalize team names to abbreviations, then attach elo_for/elo_against.\n",
    "    Assumes schedule_df has: date, home_team, away_team, home, opponent, back_to_back, rest_days, rest_diff.\n",
    "    \"\"\"\n",
    "    sch = schedule_df.copy()\n",
    "\n",
    "    sch[\"home_team\"] = sch[\"home_team\"].map(NAME_TO_ABBR).fillna(sch[\"home_team\"])\n",
    "    sch[\"away_team\"] = sch[\"away_team\"].map(NAME_TO_ABBR).fillna(sch[\"away_team\"])\n",
    "\n",
    "    sch[\"home\"] = (sch[\"home_team\"] == team_abbr).astype(int)\n",
    "    sch[\"opponent\"] = np.where(sch[\"home\"] == 1, sch[\"away_team\"], sch[\"home_team\"])\n",
    "\n",
    "    sch[\"elo_for\"] = np.where(sch[\"home\"] == 1, sch[\"home_team\"].map(elo_map), sch[\"away_team\"].map(elo_map))\n",
    "    sch[\"elo_against\"] = np.where(sch[\"home\"] == 1, sch[\"away_team\"].map(elo_map), sch[\"home_team\"].map(elo_map))\n",
    "\n",
    "    cols = [\"date\",\"home_team\",\"away_team\",\"opponent\",\"home\",\"back_to_back\",\"rest_days\",\"rest_diff\",\"elo_for\",\"elo_against\"]\n",
    "    extra = [c for c in [\"Location\",\"Result\",\"Match Number\",\"Round Number\"] if c in sch.columns]\n",
    "    return sch[cols + extra]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not find a stat column in skaters among ('GS/GP', 'gs_per_gp', 'gs_gp', 'GAR', 'xGAR', 'WAR', 'points_per_game', 'p_per_gp', 'p/GP')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m SKATERS_CSV = \u001b[33m\"\u001b[39m\u001b[33m../data/raw/skaters.csv\u001b[39m\u001b[33m\"\u001b[39m         \u001b[38;5;66;03m# season skater stats used for impact\u001b[39;00m\n\u001b[32m      5\u001b[39m TEAM_ABBR = \u001b[33m\"\u001b[39m\u001b[33mTOR\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m elo_bump, bump_details = \u001b[43mcompute_offseason_bump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTXN_CSV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSKATERS_CSV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melo_per_std\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m60.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m({\u001b[33m\"\u001b[39m\u001b[33melo_bump_TOR\u001b[39m\u001b[33m\"\u001b[39m: elo_bump})\n\u001b[32m      9\u001b[39m display(bump_details.head(\u001b[32m10\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mcompute_offseason_bump\u001b[39m\u001b[34m(transactions_csv, skaters_csv, stat_candidates, direction_col_candidates, player_col_candidates_txn, player_col_candidates_sk, season_col_candidates_sk, weight_col_candidates_txn, elo_per_std, min_gp, acquired_tokens, departed_tokens)\u001b[39m\n\u001b[32m     37\u001b[39m stat_col = _pick_col(sk, stat_candidates)\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stat_col \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not find a stat column in skaters among \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstat_candidates\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     40\u001b[39m gp_col = _pick_col(sk, (\u001b[33m\"\u001b[39m\u001b[33mgp\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mGP\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mgames\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mGames\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Normalize names\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Could not find a stat column in skaters among ('GS/GP', 'gs_per_gp', 'gs_gp', 'GAR', 'xGAR', 'WAR', 'points_per_game', 'p_per_gp', 'p/GP')"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def predict_schedule(sch_df: pd.DataFrame, backtest_csv: str,\n",
    "                     n_sims: int = 0,  rng_seed: int | None = None,\n",
    "                     use_elo_noise: bool = False, elo_noise_sd: float = 35.0):\n",
    "\n",
    "    sch = sch_df.copy().reset_index(drop=True)\n",
    "\n",
    "    diff_base = (\n",
    "        (sch[\"elo_for\"].astype(float) - sch[\"elo_against\"].astype(float))\n",
    "        + HOME_EDGE * sch[\"home\"].astype(int)\n",
    "        - B2B_PENALTY * sch[\"back_to_back\"].astype(int)\n",
    "        + REST_PTS_PER_DAY * sch[\"rest_diff\"].astype(float)\n",
    "    ).values\n",
    "    p_elo = 1.0 / (1.0 + 10.0 ** (-(diff_base) / ELO_SCALE_DEN))\n",
    "    p_base = ALPHA_ELO * p_elo + (1.0 - ALPHA_ELO) * 0.5\n",
    "    p_base = np.clip(p_base, 1e-6, 1 - 1e-6)\n",
    "\n",
    "    bt = pd.read_csv(backtest_csv)\n",
    "\n",
    "    res = bt[\"result\"].astype(str).str.strip().str.upper()\n",
    "\n",
    "    ext = bt.get(\"extra_time\", \"no\")\n",
    "    ext = pd.Series(ext).fillna(\"no\").astype(str).str.strip().str.lower()\n",
    "    ext = ext.replace({\n",
    "        \"overtime\": \"ot\", \"otl\": \"ot\", \"ot/so\": \"ot\",\n",
    "        \"shootout\": \"so\", \"shoot-out\": \"so\",\n",
    "        \"\": \"no\"\n",
    "    })\n",
    "    beyond = (ext != \"no\")\n",
    "    if \"so\" in bt.columns:\n",
    "        so_col = pd.to_numeric(bt[\"so\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "        beyond = beyond | (so_col == 1)\n",
    "\n",
    "    wins_true = (res == \"W\").astype(int).values\n",
    "    otl_true  = ((res == \"L\") & beyond).astype(int).values\n",
    "    losses_true = int((wins_true == 0).sum())\n",
    "    p_otl = (int(otl_true.sum()) / losses_true) if losses_true > 0 else 0.0\n",
    "    p_otl = float(np.clip(p_otl, 0.0, 1.0))\n",
    "\n",
    "    base_cols = [c for c in [\"date\",\"home_team\",\"away_team\",\"opponent\",\"home\",\n",
    "                             \"back_to_back\",\"rest_days\",\"rest_diff\",\"elo_for\",\"elo_against\"]\n",
    "                 if c in sch.columns]\n",
    "\n",
    "    if n_sims == 0:\n",
    "        preds = sch[base_cols].copy()\n",
    "        preds[\"win_prob\"] = np.round(p_base, 3)\n",
    "        pred_win = (p_base >= 0.5).astype(int)\n",
    "        loss_idx = np.where(pred_win == 0)[0]\n",
    "\n",
    "        otl_idx = allocate_otl(loss_idx, p_base, p_otl) if len(loss_idx) else set()\n",
    "\n",
    "        res_cat = np.array([\"W\"] * len(preds), dtype=object)\n",
    "        if len(loss_idx):\n",
    "            res_cat[loss_idx] = \"L\"\n",
    "            if otl_idx:\n",
    "                res_cat[list(otl_idx)] = \"OTL\"\n",
    "        preds[\"predicted_result\"] = res_cat\n",
    "\n",
    "        pred_w  = int((preds[\"predicted_result\"] == \"W\").sum())\n",
    "        pred_ol = int((preds[\"predicted_result\"] == \"OTL\").sum())\n",
    "        pred_rl = int((preds[\"predicted_result\"] == \"L\").sum())\n",
    "        summary = {\n",
    "            \"n_games\": len(preds),\n",
    "            \"pred_record_W-L-OTL\": f\"{pred_w}-{pred_rl}-{pred_ol}\",\n",
    "            \"pred_points\": int(2 * pred_w + pred_ol),\n",
    "            \"avg_win_prob\": float(preds[\"win_prob\"].mean()),\n",
    "            \"assumed_otl_share_from_backtest\": round(p_otl, 3),\n",
    "            \"mode\": \"deterministic\",\n",
    "        }\n",
    "        return preds, None, summary\n",
    "\n",
    "    rng = np.random.default_rng(None if rng_seed is None else rng_seed)  # <- None => fresh entropy\n",
    "    n_games = len(sch)\n",
    "    wins_sims = np.zeros((n_sims, n_games), dtype=int)\n",
    "    otl_sims  = np.zeros((n_sims, n_games), dtype=int)\n",
    "\n",
    "    for s in range(n_sims):\n",
    "        if use_elo_noise:\n",
    "            diff = diff_base + rng.normal(0.0, elo_noise_sd, size=n_games)\n",
    "            p_e = 1.0 / (1.0 + 10.0 ** (-(diff) / ELO_SCALE_DEN))\n",
    "            p   = ALPHA_ELO * p_e + (1.0 - ALPHA_ELO) * 0.5\n",
    "            p   = np.clip(p, 1e-6, 1 - 1e-6)\n",
    "        else:\n",
    "            p = p_base\n",
    "\n",
    "        w = rng.binomial(1, p, size=n_games)\n",
    "        wins_sims[s] = w\n",
    "\n",
    "        loss_positions = np.where(w == 0)[0]\n",
    "        if len(loss_positions) > 0 and p_otl > 0.0:\n",
    "            otl_flags = rng.binomial(1, p_otl, size=len(loss_positions))\n",
    "            otl_sims[s, loss_positions] = otl_flags\n",
    "\n",
    "    # mean-rule for wins\n",
    "    win_rate = wins_sims.mean(axis=0)\n",
    "\n",
    "    # display-case: W by mean-rule; OTL allocated among remaining losses by backtest share\n",
    "    display_result = np.full(n_games, \"L\", dtype=object)\n",
    "    display_result[win_rate >= 0.5] = \"W\"\n",
    "\n",
    "#allocate OT\n",
    "    remaining_losses = np.where(win_rate < 0.5)[0]\n",
    "    otl_pick = allocate_otl(remaining_losses, p_base, p_otl) if len(remaining_losses) else set()\n",
    "    if otl_pick:\n",
    "        display_result[list(otl_pick)] = \"OTL\"\n",
    "\n",
    "    display_df = sch[base_cols].copy()\n",
    "    display_df[\"win_prob\"] = np.round(p_base, 3)\n",
    "    display_df[\"win_rate\"] = np.round(win_rate, 3)\n",
    "    display_df[\"display_result\"] = display_result\n",
    "\n",
    "    # per-sim totals (for histogram)\n",
    "    rows = []\n",
    "    for s in range(n_sims):\n",
    "        w = int(wins_sims[s].sum())\n",
    "        losses_idx = np.where(wins_sims[s] == 0)[0]\n",
    "        ol = int(otl_sims[s, losses_idx].sum()) if len(losses_idx) else 0\n",
    "        rl = int(len(losses_idx) - ol)\n",
    "        pts = int(2 * w + ol)\n",
    "        rows.append({\"sim\": s, \"wins\": w, \"reg_losses\": rl, \"otl\": ol, \"points\": pts,\n",
    "                     \"record_W-L-OTL\": f\"{w}-{rl}-{ol}\"})\n",
    "    sims_totals = pd.DataFrame(rows)\n",
    "\n",
    "    # summary\n",
    "    disp_w  = int((display_df[\"display_result\"] == \"W\").sum())\n",
    "    disp_ol = int((display_df[\"display_result\"] == \"OTL\").sum())\n",
    "    disp_rl = int((display_df[\"display_result\"] == \"L\").sum())\n",
    "    summary = {\n",
    "        \"n_games\": n_games,\n",
    "        \"display_record_W-L-OTL\": f\"{disp_w}-{disp_rl}-{disp_ol}\",\n",
    "        \"display_points\": int(2 * disp_w + disp_ol),\n",
    "        \"mean_points\": float(sims_totals[\"points\"].mean()),\n",
    "        \"median_points\": float(sims_totals[\"points\"].median()),\n",
    "        \"assumed_otl_share_from_backtest\": round(p_otl, 3),\n",
    "        \"n_sims\": n_sims,\n",
    "        \"mode\": \"simulation_mean_rule\",\n",
    "    }\n",
    "    return display_df, sims_totals, summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'elo_bump_TOR': -7}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>team_from</th>\n",
       "      <th>team_to</th>\n",
       "      <th>gs_per_gp</th>\n",
       "      <th>contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mitch Marner</td>\n",
       "      <td>TOR</td>\n",
       "      <td>VGK</td>\n",
       "      <td>1.081975</td>\n",
       "      <td>-1.081975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Matias Maccelli</td>\n",
       "      <td>UTA</td>\n",
       "      <td>TOR</td>\n",
       "      <td>0.462727</td>\n",
       "      <td>0.462727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dakota Joshua</td>\n",
       "      <td>VAN</td>\n",
       "      <td>TOR</td>\n",
       "      <td>0.136667</td>\n",
       "      <td>0.136667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nicolas Roy</td>\n",
       "      <td>VGK</td>\n",
       "      <td>TOR</td>\n",
       "      <td>0.427746</td>\n",
       "      <td>0.427746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            player team_from team_to  gs_per_gp  contribution\n",
       "0     Mitch Marner       TOR     VGK   1.081975     -1.081975\n",
       "1  Matias Maccelli       UTA     TOR   0.462727      0.462727\n",
       "2    Dakota Joshua       VAN     TOR   0.136667      0.136667\n",
       "3      Nicolas Roy       VGK     TOR   0.427746      0.427746"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted record (W-L-OTL): 41-36-5 | Points: 87\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(         date home_team away_team opponent  home  back_to_back  rest_days  \\\n",
       " 0  2025-10-08       TOR       MTL      MTL     1             0          2   \n",
       " 1  2025-10-11       DET       TOR      DET     0             0          3   \n",
       " 2  2025-10-13       TOR       DET      DET     1             0          2   \n",
       " 3  2025-10-14       TOR       NSH      NSH     1             1          1   \n",
       " 4  2025-10-16       TOR       NYR      NYR     1             0          2   \n",
       " ..        ...       ...       ...      ...   ...           ...        ...   \n",
       " 77 2026-04-08       TOR       WSH      WSH     1             0          4   \n",
       " 78 2026-04-09       NYI       TOR      NYI     0             1          1   \n",
       " 79 2026-04-11       TOR       FLA      FLA     1             0          2   \n",
       " 80 2026-04-13       TOR       DAL      DAL     1             0          2   \n",
       " 81 2026-04-15       OTT       TOR      OTT     0             0          2   \n",
       " \n",
       "     rest_diff      elo_for  elo_against  win_prob  win_rate display_result  \n",
       " 0           0  1501.123969  1408.218896     0.560      0.50              W  \n",
       " 1           0  1501.123969  1442.899590     0.536      0.49              L  \n",
       " 2           0  1501.123969  1442.899590     0.539      0.45              L  \n",
       " 3           0  1501.123969  1487.773147     0.505      0.49            OTL  \n",
       " 4           0  1501.123969  1478.252309     0.517      0.51              W  \n",
       " ..        ...          ...          ...       ...       ...            ...  \n",
       " 77          0  1501.123969  1549.680981     0.473      0.46              L  \n",
       " 78          0  1501.123969  1452.205223     0.524      0.50              W  \n",
       " 79          0  1501.123969  1632.535450     0.423      0.41              L  \n",
       " 80          0  1501.123969  1532.127545     0.484      0.51              W  \n",
       " 81          0  1501.123969  1463.979350     0.523      0.40              L  \n",
       " \n",
       " [82 rows x 13 columns],\n",
       "     sim  wins  reg_losses  otl  points record_W-L-OTL\n",
       " 0     0    40          36    6      86        40-36-6\n",
       " 1     1    46          31    5      97        46-31-5\n",
       " 2     2    40          36    6      86        40-36-6\n",
       " 3     3    38          41    3      79        38-41-3\n",
       " 4     4    32          42    8      72        32-42-8\n",
       " ..  ...   ...         ...  ...     ...            ...\n",
       " 95   95    39          37    6      84        39-37-6\n",
       " 96   96    39          36    7      85        39-36-7\n",
       " 97   97    37          38    7      81        37-38-7\n",
       " 98   98    35          40    7      77        35-40-7\n",
       " 99   99    42          37    3      87        42-37-3\n",
       " \n",
       " [100 rows x 6 columns],\n",
       " {'n_games': 82,\n",
       "  'display_record_W-L-OTL': '41-36-5',\n",
       "  'display_points': 87,\n",
       "  'mean_points': 85.96,\n",
       "  'median_points': 86.0,\n",
       "  'assumed_otl_share_from_backtest': 0.133,\n",
       "  'n_sims': 100,\n",
       "  'mode': 'simulation_mean_rule'})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 1) Load schedule (parses DD/MM/YYYY and adds rest features)\n",
    "schedule_df = load_leafs_schedule_from_csv(SCHEDULE_CSV)\n",
    "\n",
    "# 2) Build team Elo map from latest season composites\n",
    "elo_map, _ = build_elo_map(TEAMS_CSV, SAVE_PCT_CSV)\n",
    "# --- Apply offseason bump to TOR and re-attach Elo to schedule ---\n",
    "\n",
    "\n",
    "# 3) Attach Elo to schedule (Leafs = TOR)\n",
    "sch_with_elos = attach_elo_to_schedule(schedule_df, elo_map, team_abbr=\"TOR\")\n",
    "\n",
    "TXN_CSV = \"../data/clean/transactions.csv\"\n",
    "SKATERS_CSV = \"../data/raw/skaters.csv\"\n",
    "TEAM_ABBR = \"TOR\"\n",
    "\n",
    "elo_bump, bump_details = compute_offseason_bump_for_team(TXN_CSV, SKATERS_CSV, TEAM_ABBR, elo_per_std=40.0)\n",
    "print({\"elo_bump_TOR\": elo_bump})\n",
    "display(bump_details.head(10))\n",
    "\n",
    "# Apply bump in memory\n",
    "elo_map[TEAM_ABBR] = float(elo_map.get(TEAM_ABBR, 1500.0)) + float(elo_bump)\n",
    "\n",
    "\n",
    "# Re-attach to schedule\n",
    "schedule_with_bump = attach_elo_to_schedule(schedule_df, elo_map, team_abbr=TEAM_ABBR)\n",
    "\n",
    "# 4) Predict with simulations (set n_sims=0 for deterministic)\n",
    "display_df, sims_totals, summary = predict_schedule(\n",
    "    sch_df=sch_with_elos,\n",
    "    backtest_csv=BACKTEST_CSV,\n",
    "    n_sims=100,\n",
    "    rng_seed=7,\n",
    "    use_elo_noise=False\n",
    ")\n",
    "\n",
    "# After: preds_df_or_display_df, sims_totals_or_None, summary = predict_schedule(...)\n",
    "rec = summary.get(\"display_record_W-L-OTL\", summary.get(\"pred_record_W-L-OTL\"))\n",
    "pts = summary.get(\"display_points\", summary.get(\"pred_points\"))\n",
    "print(f\"Predicted record (W-L-OTL): {rec} | Points: {pts}\")\n",
    "\n",
    "\n",
    "# Return the results of the function\n",
    "display_df, sims_totals, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOR components:\n",
      " team      ev_z     pp_z      pk_z    sv_z  z_composite         elo\n",
      " TOR -0.055957 1.139797 -1.686823 1.39756      0.01124 1501.123969\n",
      "NaN flags (ev_z/pp_z/pk_z/sv_z): {'ev_z': False, 'pp_z': False, 'pk_z': False, 'sv_z': False}\n",
      "z_composite percentile: 1.000\n",
      "\n",
      "Top 5 by Elo:\n",
      "team         elo\n",
      " CAR 1638.924600\n",
      " FLA 1632.535450\n",
      " VGK 1605.298458\n",
      " LAK 1605.098900\n",
      " WPG 1598.478975\n",
      "\n",
      "Bottom 5 by Elo:\n",
      "team         elo\n",
      " SJS 1326.250500\n",
      " CHI 1360.261820\n",
      " ANA 1375.575028\n",
      " SEA 1404.287344\n",
      " MTL 1408.218896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k_/559_7kh91xgfmdkgt0c3cb000000gn/T/ipykernel_29568/3504020233.py:16: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  pctl = float(comp_diag.loc[comp_diag[\"team\"] == \"TOR\", \"z_composite\"].rank(pct=True))\n"
     ]
    }
   ],
   "source": [
    "# --- Minimal TOR Elo diagnosis (works with main2.ipynb) ---\n",
    "\n",
    "# Rebuild the composite table fresh\n",
    "_, comp_diag = build_elo_map(TEAMS_CSV, SAVE_PCT_CSV)\n",
    "\n",
    "# Grab TOR row and print key pieces\n",
    "tor = comp_diag.loc[comp_diag[\"team\"] == \"TOR\", [\"team\",\"ev_z\",\"pp_z\",\"pk_z\",\"sv_z\",\"z_composite\",\"elo\"]]\n",
    "assert not tor.empty, \"TOR not found — check team codes in teams.csv and NAME_TO_ABBR.\"\n",
    "print(\"TOR components:\\n\", tor.to_string(index=False))\n",
    "\n",
    "# Simple health check for missing inputs\n",
    "nan_flags = tor[[\"ev_z\",\"pp_z\",\"pk_z\",\"sv_z\"]].isna().to_dict(\"records\")[0]\n",
    "print(\"NaN flags (ev_z/pp_z/pk_z/sv_z):\", nan_flags)\n",
    "\n",
    "# Percentile context and league extremes\n",
    "pctl = float(comp_diag.loc[comp_diag[\"team\"] == \"TOR\", \"z_composite\"].rank(pct=True))\n",
    "print(f\"z_composite percentile: {pctl:.3f}\")\n",
    "\n",
    "print(\"\\nTop 5 by Elo:\")\n",
    "print(comp_diag.sort_values(\"elo\", ascending=False)[[\"team\",\"elo\"]].head(5).to_string(index=False))\n",
    "\n",
    "print(\"\\nBottom 5 by Elo:\")\n",
    "print(comp_diag.sort_values(\"elo\", ascending=True)[[\"team\",\"elo\"]].head(5).to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
