{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup & config\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import brier_score_loss, roc_auc_score\n",
    "\n",
    "# Team context\n",
    "TEAM = \"TOR\"\n",
    "\n",
    "# Full name -> abbreviation\n",
    "NAME_TO_ABBR = {\n",
    "    \"Anaheim Ducks\": \"ANA\",\"Arizona Coyotes\": \"ARI\",\"Boston Bruins\": \"BOS\",\"Buffalo Sabres\": \"BUF\",\n",
    "    \"Calgary Flames\": \"CGY\",\"Carolina Hurricanes\": \"CAR\",\"Chicago Blackhawks\": \"CHI\",\"Colorado Avalanche\": \"COL\",\n",
    "    \"Columbus Blue Jackets\": \"CBJ\",\"Dallas Stars\": \"DAL\",\"Detroit Red Wings\": \"DET\",\"Edmonton Oilers\": \"EDM\",\n",
    "    \"Florida Panthers\": \"FLA\",\"Los Angeles Kings\": \"LAK\",\"Minnesota Wild\": \"MIN\",\"Montreal Canadiens\": \"MTL\",\n",
    "    \"Nashville Predators\": \"NSH\",\"New Jersey Devils\": \"NJD\",\"New York Islanders\": \"NYI\",\"New York Rangers\": \"NYR\",\n",
    "    \"Ottawa Senators\": \"OTT\",\"Philadelphia Flyers\": \"PHI\",\"Pittsburgh Penguins\": \"PIT\",\"San Jose Sharks\": \"SJS\",\n",
    "    \"Seattle Kraken\": \"SEA\",\"St. Louis Blues\": \"STL\",\"Tampa Bay Lightning\": \"TBL\",\"Toronto Maple Leafs\": \"TOR\",\n",
    "    \"Utah Hockey Club\": \"UTA\",\"Vancouver Canucks\": \"VAN\",\"Vegas Golden Knights\": \"VGK\",\"Washington Capitals\": \"WSH\",\n",
    "    \"Winnipeg Jets\": \"WPG\"\n",
    "}\n",
    "SCHEDULE_CSV = \"../data/raw/schedule.csv\"\n",
    "TEAMS_CSV = \"../data/raw/teams.csv\"\n",
    "SAVE_PCT_CSV = \"../data/clean/team_save_percentages.csv\"\n",
    "BACKTEST_CSV = \"../data/raw/backtest.csv\"\n",
    "\n",
    "# Elo knobs (deterministic)\n",
    "HOME_EDGE = 5.0           # Elo pts for home ice\n",
    "B2B_PENALTY = 10.0        # Elo pts penalty for back-to-back\n",
    "REST_PTS_PER_DAY = 3.0    # Elo pts per rest_diff day\n",
    "ELO_SCALE_DEN = 600.0     # larger => flatter probabilities\n",
    "ALPHA_ELO = 0.65          # 1.0 => pure Elo, 0.0 => coin flip\n",
    "\n",
    "def elo_prob_row(row: pd.Series) -> float:\n",
    "    \"\"\"Deterministic win probability from Elo + simple context tweaks.\"\"\"\n",
    "    diff = float(row[\"elo_for\"]) - float(row[\"elo_against\"])\n",
    "    if int(row[\"home\"]) == 1:\n",
    "        diff += HOME_EDGE\n",
    "    if int(row[\"back_to_back\"]) == 1:\n",
    "        diff -= B2B_PENALTY\n",
    "    diff += REST_PTS_PER_DAY * float(row.get(\"rest_diff\", 0))\n",
    "    p_elo = 1.0 / (1.0 + 10.0 ** (-(diff) / ELO_SCALE_DEN))\n",
    "    return float(ALPHA_ELO * p_elo + (1.0 - ALPHA_ELO) * 0.5)\n",
    "\n",
    "def allocate_otl(loss_idx: np.ndarray, probs: np.ndarray, expected_share: float) -> set:\n",
    "    \"\"\"\n",
    "    Mark a subset of predicted losses as OTL to match an expected share.\n",
    "    Picks the losses whose probs are closest to 0.5.\n",
    "    \"\"\"\n",
    "    n = len(loss_idx)\n",
    "    k = int(round(max(0.0, min(1.0, expected_share)) * n))\n",
    "    if n == 0 or k == 0:\n",
    "        return set()\n",
    "    closeness = np.abs(probs[loss_idx] - 0.5)\n",
    "    otl_pick = loss_idx[np.argsort(closeness)[:k]]\n",
    "    return set(otl_pick)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load shed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_leafs_schedule_from_csv(\n",
    "    csv_path: str,\n",
    "    team_abbr: str = TEAM,\n",
    "    date_col: str = \"Date\",\n",
    "    home_col: str = \"Home Team\",\n",
    "    away_col: str = \"Away Team\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load a FixtureDownload-style Leafs schedule and return:\n",
    "      date (datetime64[ns]), home_team, away_team, opponent, home,\n",
    "      back_to_back, rest_days, rest_diff (placeholder=0),\n",
    "      plus passthrough columns if present: Location, Result, Match Number, Round Number.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Normalize column names we need\n",
    "    for col in (date_col, home_col, away_col):\n",
    "        if col not in df.columns:\n",
    "            raise KeyError(f\"Expected column '{col}' not found. Got: {list(df.columns)}\")\n",
    "    df = df.rename(columns={date_col: \"date\", home_col: \"home_team\", away_col: \"away_team\"})\n",
    "\n",
    "    # Keep a tidy subset (preserve useful references if present)\n",
    "    keep = [\"date\", \"home_team\", \"away_team\"]\n",
    "    for opt in [\"Location\", \"Result\", \"Match Number\", \"Round Number\"]:\n",
    "        if opt in df.columns:\n",
    "            keep.append(opt)\n",
    "    df = df[keep].copy()\n",
    "\n",
    "    # Robust date parsing: your CSV is DD/MM/YYYY; also accept ISO if present\n",
    "    date_str = df[\"date\"].astype(str).str.strip()\n",
    "    parsed = pd.to_datetime(date_str, format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "    na = parsed.isna()\n",
    "    if na.any():  # try generic parse for lingering ISO etc.\n",
    "        parsed.loc[na] = pd.to_datetime(date_str[na], errors=\"coerce\")\n",
    "    df[\"date\"] = parsed\n",
    "\n",
    "    # Leafs POV\n",
    "    df[\"home\"] = (df[\"home_team\"] == team_abbr).astype(int)\n",
    "    df[\"opponent\"] = np.where(df[\"home\"] == 1, df[\"away_team\"], df[\"home_team\"])\n",
    "\n",
    "    # Vectorized rest features\n",
    "    df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "    d_days = df[\"date\"].diff().dt.days.fillna(2).clip(lower=0).astype(int)\n",
    "    df[\"rest_days\"] = d_days\n",
    "    df[\"back_to_back\"] = (d_days == 1).astype(int)\n",
    "\n",
    "    # Placeholder until opponent rest is computed\n",
    "    df[\"rest_diff\"] = 0\n",
    "\n",
    "    # Order columns\n",
    "    order = [\"date\",\"home_team\",\"away_team\",\"opponent\",\"home\",\"back_to_back\",\"rest_days\",\"rest_diff\"]\n",
    "    for opt in [\"Location\", \"Result\", \"Match Number\", \"Round Number\"]:\n",
    "        if opt in df.columns:\n",
    "            order.append(opt)\n",
    "    return df[order]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "elo mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_elo_map(\n",
    "    teams_csv: str = \"../data/raw/teams.csv\",\n",
    "    save_pct_csv: str = \"../data/clean/team_save_percentages.csv\",\n",
    ") -> tuple[dict, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Build a composite strength metric (EV/PP/PK + Save%) and map to Elo.\n",
    "    Returns (elo_map: dict[abbr->elo], comp_df).\n",
    "    \"\"\"\n",
    "    teams_df = pd.read_csv(teams_csv).copy()\n",
    "    teams_df[\"season\"] = pd.to_numeric(teams_df[\"season\"], errors=\"coerce\")\n",
    "    latest_season = int(teams_df[\"season\"].max())\n",
    "\n",
    "    t = teams_df.loc[teams_df[\"season\"] == latest_season, [\"team\",\"situation\",\"iceTime\",\"xGoalsFor\",\"xGoalsAgainst\"]].copy()\n",
    "    SIT_MAP = {\"5on5\":\"EV\", \"5on4\":\"PP\", \"4on5\":\"PK\"}\n",
    "    t[\"SIT\"] = t[\"situation\"].map(SIT_MAP)\n",
    "\n",
    "    # Rates per 60\n",
    "    t[\"iceTime\"] = pd.to_numeric(t[\"iceTime\"], errors=\"coerce\").replace(0, np.nan)\n",
    "    t[\"xGoalsFor\"] = pd.to_numeric(t[\"xGoalsFor\"], errors=\"coerce\")\n",
    "    t[\"xGoalsAgainst\"] = pd.to_numeric(t[\"xGoalsAgainst\"], errors=\"coerce\")\n",
    "    t[\"xGF60\"] = (t[\"xGoalsFor\"] / t[\"iceTime\"]) * 60.0\n",
    "    t[\"xGA60\"] = (t[\"xGoalsAgainst\"] / t[\"iceTime\"]) * 60.0\n",
    "    t[\"net_xG60\"] = t[\"xGF60\"] - t[\"xGA60\"]\n",
    "\n",
    "    # Aggregate by situation\n",
    "    pp = t.loc[t[\"SIT\"]==\"PP\"].groupby(\"team\", as_index=False)[[\"xGF60\"]].mean()\n",
    "    pk = t.loc[t[\"SIT\"]==\"PK\"].groupby(\"team\", as_index=False)[[\"xGA60\"]].mean()\n",
    "    ev = t.loc[t[\"SIT\"]==\"EV\"].groupby(\"team\", as_index=False)[[\"net_xG60\"]].mean()\n",
    "\n",
    "    # Fill with league means to avoid gaps\n",
    "    all_teams = pd.DataFrame({\"team\": t[\"team\"].dropna().unique()})\n",
    "    pp = all_teams.merge(pp, on=\"team\", how=\"left\");  pp[\"xGF60\"] = pp[\"xGF60\"].fillna(pp[\"xGF60\"].mean())\n",
    "    pk = all_teams.merge(pk, on=\"team\", how=\"left\");  pk[\"xGA60\"] = pk[\"xGA60\"].fillna(pk[\"xGA60\"].mean())\n",
    "    ev = all_teams.merge(ev, on=\"team\", how=\"left\");  ev[\"net_xG60\"] = ev[\"net_xG60\"].fillna(ev[\"net_xG60\"].mean())\n",
    "\n",
    "    # z-scores (with safe denominator)\n",
    "    def z(s: pd.Series) -> pd.Series:\n",
    "        s = s.astype(float)\n",
    "        mu = s.mean()\n",
    "        sd = s.std(ddof=0)\n",
    "        return (s - mu) / (sd if sd != 0 else 1.0)\n",
    "\n",
    "    ev_z = z(ev[\"net_xG60\"])            # higher better\n",
    "    pp_z = z(pp[\"xGF60\"])               # higher better\n",
    "    # PK: lower xGA60 is better -> invert before z\n",
    "    pk_z = z(-pk[\"xGA60\"])\n",
    "\n",
    "    # Goalie save % (map full names -> abbr to match others)\n",
    "    sv_df = pd.read_csv(save_pct_csv).rename(columns={\"team\":\"team_name\",\"savePct\":\"savePct\"})\n",
    "    sv_df[\"team\"] = sv_df[\"team_name\"].map(NAME_TO_ABBR)\n",
    "    sv = all_teams.merge(sv_df[[\"team\",\"savePct\"]], on=\"team\", how=\"left\")\n",
    "    sv[\"savePct\"] = pd.to_numeric(sv[\"savePct\"], errors=\"coerce\")\n",
    "    sv[\"savePct\"] = sv[\"savePct\"].fillna(sv[\"savePct\"].mean())\n",
    "    sv_z = z(sv[\"savePct\"])\n",
    "\n",
    "    # Composite -> Elo\n",
    "    W_EV, W_PP, W_PK, W_SV = 0.60, 0.20, 0.15, 0.05\n",
    "    comp = all_teams.copy()\n",
    "    comp[\"ev_z\"] = ev_z.values\n",
    "    comp[\"pp_z\"] = pp_z.values\n",
    "    comp[\"pk_z\"] = pk_z.values\n",
    "    comp[\"sv_z\"] = sv_z.values\n",
    "    comp[\"z_composite\"] = W_EV*comp[\"ev_z\"] + W_PP*comp[\"pp_z\"] + W_PK*comp[\"pk_z\"] + W_SV*comp[\"sv_z\"]\n",
    "    comp[\"elo\"] = 1500.0 + 100.0 * comp[\"z_composite\"]\n",
    "\n",
    "    elo_map = dict(zip(comp[\"team\"], comp[\"elo\"]))\n",
    "    return elo_map, comp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attach to sched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_elo_to_schedule(schedule_df: pd.DataFrame, elo_map: dict, team_abbr: str = TEAM) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Normalize team names to abbreviations, then attach elo_for/elo_against.\n",
    "    Assumes schedule_df has: date, home_team, away_team, home, opponent, back_to_back, rest_days, rest_diff.\n",
    "    \"\"\"\n",
    "    sch = schedule_df.copy()\n",
    "\n",
    "    # Normalize to abbreviations if full names are present\n",
    "    sch[\"home_team\"] = sch[\"home_team\"].map(NAME_TO_ABBR).fillna(sch[\"home_team\"])\n",
    "    sch[\"away_team\"] = sch[\"away_team\"].map(NAME_TO_ABBR).fillna(sch[\"away_team\"])\n",
    "\n",
    "    # Recompute home/opponent from abbr to be safe\n",
    "    sch[\"home\"] = (sch[\"home_team\"] == team_abbr).astype(int)\n",
    "    sch[\"opponent\"] = np.where(sch[\"home\"] == 1, sch[\"away_team\"], sch[\"home_team\"])\n",
    "\n",
    "    # Attach Elo\n",
    "    sch[\"elo_for\"] = np.where(sch[\"home\"] == 1, sch[\"home_team\"].map(elo_map), sch[\"away_team\"].map(elo_map))\n",
    "    sch[\"elo_against\"] = np.where(sch[\"home\"] == 1, sch[\"away_team\"].map(elo_map), sch[\"home_team\"].map(elo_map))\n",
    "\n",
    "    # Keep tidy\n",
    "    cols = [\"date\",\"home_team\",\"away_team\",\"opponent\",\"home\",\"back_to_back\",\"rest_days\",\"rest_diff\",\"elo_for\",\"elo_against\"]\n",
    "    extra = [c for c in [\"Location\",\"Result\",\"Match Number\",\"Round Number\"] if c in sch.columns]\n",
    "    return sch[cols + extra]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def predict_schedule(\n",
    "    sch_df: pd.DataFrame,\n",
    "    backtest_csv: str = \"../data/raw/backtest.csv\",\n",
    "    n_sims: int = 0,\n",
    "    rng_seed: int = 42,\n",
    "    use_elo_noise: bool = False,\n",
    "    elo_noise_sd: float = 35.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    n_sims == 0 -> deterministic predictions with OTL allocation.\n",
    "    n_sims  > 0 -> simulations; display-case per game via MEAN wins + OTL allocated\n",
    "                   among display losses to match backtest share.\n",
    "    Returns:\n",
    "      if n_sims == 0: (preds_df, None, summary)\n",
    "      else:           (display_df, sims_totals_df, summary)\n",
    "    \"\"\"\n",
    "    sch = sch_df.copy().reset_index(drop=True)\n",
    "\n",
    "    # ---- Base Elo probability (deterministic) ----\n",
    "    diff_base = (\n",
    "        (sch[\"elo_for\"].astype(float) - sch[\"elo_against\"].astype(float))\n",
    "        + HOME_EDGE * sch[\"home\"].astype(int)\n",
    "        - B2B_PENALTY * sch[\"back_to_back\"].astype(int)\n",
    "        + REST_PTS_PER_DAY * sch[\"rest_diff\"].astype(float)\n",
    "    ).values\n",
    "    p_elo = 1.0 / (1.0 + 10.0 ** (-(diff_base) / ELO_SCALE_DEN))\n",
    "    p_base = ALPHA_ELO * p_elo + (1.0 - ALPHA_ELO) * 0.5\n",
    "    p_base = np.clip(p_base, 1e-6, 1 - 1e-6)\n",
    "\n",
    "    # ---- Robust OTL share from backtest (SO counts as OTL) ----\n",
    "    bt = pd.read_csv(backtest_csv)\n",
    "    # normalize result\n",
    "    res = bt[\"result\"].astype(str).str.strip().str.upper()\n",
    "    # normalize extra_time and treat any non-\"no\" as beyond regulation\n",
    "    ext = bt.get(\"extra_time\", \"no\")\n",
    "    ext = pd.Series(ext).fillna(\"no\").astype(str).str.strip().str.lower()\n",
    "    ext = ext.replace({\n",
    "        \"overtime\": \"ot\", \"otl\": \"ot\", \"ot/so\": \"ot\",\n",
    "        \"shootout\": \"so\", \"shoot-out\": \"so\",\n",
    "        \"\": \"no\"  # blank -> no\n",
    "    })\n",
    "    beyond = ext != \"no\"\n",
    "    if \"so\" in bt.columns:\n",
    "        so_col = pd.to_numeric(bt[\"so\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "        beyond = beyond | (so_col == 1)\n",
    "\n",
    "    wins_true = (res == \"W\").astype(int).values\n",
    "    otl_true = ((res == \"L\") & beyond).astype(int).values\n",
    "    losses_true = int((wins_true == 0).sum())\n",
    "    p_otl = (int(otl_true.sum()) / losses_true) if losses_true > 0 else 0.0\n",
    "    p_otl = float(np.clip(p_otl, 0.0, 1.0))\n",
    "\n",
    "    base_cols = [c for c in [\"date\",\"home_team\",\"away_team\",\"opponent\",\"home\",\"back_to_back\",\"rest_diff\",\"elo_for\",\"elo_against\"] if c in sch.columns]\n",
    "\n",
    "    # ======================\n",
    "    # Deterministic path\n",
    "    # ======================\n",
    "    if n_sims == 0:\n",
    "        preds = sch[base_cols].copy()\n",
    "        preds[\"win_prob\"] = np.round(p_base, 3)\n",
    "\n",
    "        pred_win = (p_base >= 0.5).astype(int)\n",
    "        loss_idx = np.where(pred_win == 0)[0]\n",
    "\n",
    "        # Allocate OTLs among predicted losses to match backtest share\n",
    "        k_otl = int(round(p_otl * len(loss_idx)))\n",
    "        res_cat = np.array([\"W\"] * len(preds), dtype=object)\n",
    "        if len(loss_idx) > 0:\n",
    "            res_cat[loss_idx] = \"L\"\n",
    "            if k_otl > 0:\n",
    "                closeness = np.abs(p_base[loss_idx] - 0.5)\n",
    "                otl_pick = loss_idx[np.argsort(closeness)[:k_otl]]\n",
    "                res_cat[otl_pick] = \"OTL\"\n",
    "\n",
    "        preds[\"predicted_result\"] = res_cat\n",
    "\n",
    "        pred_w  = int((preds[\"predicted_result\"] == \"W\").sum())\n",
    "        pred_ol = int((preds[\"predicted_result\"] == \"OTL\").sum())\n",
    "        pred_rl = int((preds[\"predicted_result\"] == \"L\").sum())\n",
    "        summary = {\n",
    "            \"n_games\": len(preds),\n",
    "            \"pred_record_W-L-OTL\": f\"{pred_w}-{pred_rl}-{pred_ol}\",\n",
    "            \"pred_points\": int(2 * pred_w + pred_ol),\n",
    "            \"avg_win_prob\": float(preds[\"win_prob\"].mean()),\n",
    "            \"assumed_otl_share_from_backtest\": round(p_otl, 3),\n",
    "            \"mode\": \"deterministic\",\n",
    "        }\n",
    "        return preds, None, summary\n",
    "\n",
    "    # ======================\n",
    "    # Simulation path\n",
    "    # ======================\n",
    "    rng = np.random.default_rng(rng_seed)\n",
    "    n_games = len(sch)\n",
    "    wins_sims = np.zeros((n_sims, n_games), dtype=int)\n",
    "    otl_sims  = np.zeros((n_sims, n_games), dtype=int)\n",
    "\n",
    "    for s in range(n_sims):\n",
    "        if use_elo_noise:\n",
    "            diff = diff_base + rng.normal(0.0, elo_noise_sd, size=n_games)\n",
    "            p_e = 1.0 / (1.0 + 10.0 ** (-(diff) / ELO_SCALE_DEN))\n",
    "            p = ALPHA_ELO * p_e + (1.0 - ALPHA_ELO) * 0.5\n",
    "            p = np.clip(p, 1e-6, 1 - 1e-6)\n",
    "        else:\n",
    "            p = p_base\n",
    "        w = rng.binomial(1, p, size=n_games)\n",
    "        wins_sims[s] = w\n",
    "        loss_positions = np.where(w == 0)[0]\n",
    "        if len(loss_positions) > 0 and p_otl > 0.0:\n",
    "            otl_flags = rng.binomial(1, p_otl, size=len(loss_positions))\n",
    "            otl_sims[s, loss_positions] = otl_flags\n",
    "\n",
    "    # Per-game means\n",
    "    win_rate = wins_sims.mean(axis=0)\n",
    "    loss_count = n_sims - wins_sims.sum(axis=0)\n",
    "\n",
    "    # Display-case: W by mean-rule; OTL allocated among remaining losses by backtest share\n",
    "    display_res = np.full(n_games, \"L\", dtype=object)\n",
    "    display_res[win_rate >= 0.5] = \"W\"\n",
    "    remaining_losses = np.where(win_rate < 0.5)[0]\n",
    "    k_display_otl = int(round(p_otl * len(remaining_losses)))\n",
    "    if k_display_otl > 0 and len(remaining_losses) > 0:\n",
    "        closeness = np.abs(p_base[remaining_losses] - 0.5)\n",
    "        otl_pick = remaining_losses[np.argsort(closeness)[:k_display_otl]]\n",
    "        display_res[otl_pick] = \"OTL\"\n",
    "\n",
    "    display_df = sch[base_cols].copy()\n",
    "    display_df[\"win_prob\"] = np.round(p_base, 3)\n",
    "    display_df[\"win_rate\"] = np.round(win_rate, 3)\n",
    "    display_df[\"display_result\"] = display_res\n",
    "\n",
    "    # Per-sim totals\n",
    "    sim_rows = []\n",
    "    for s in range(n_sims):\n",
    "        w = int(wins_sims[s].sum())\n",
    "        losses_idx = np.where(wins_sims[s] == 0)[0]\n",
    "        # derive per-sim OTL count from sampled flags\n",
    "        ol = int(otl_sims[s, losses_idx].sum()) if len(losses_idx) else 0\n",
    "        rl = int(len(losses_idx) - ol)\n",
    "        pts = int(2 * w + ol)\n",
    "        sim_rows.append({\"sim\": s, \"wins\": w, \"reg_losses\": rl, \"otl\": ol, \"points\": pts,\n",
    "                         \"record_W-L-OTL\": f\"{w}-{rl}-{ol}\"})\n",
    "    sims_totals = pd.DataFrame(sim_rows)\n",
    "\n",
    "    # Summary\n",
    "    disp_w  = int((display_df[\"display_result\"] == \"W\").sum())\n",
    "    disp_ol = int((display_df[\"display_result\"] == \"OTL\").sum())\n",
    "    disp_rl = int((display_df[\"display_result\"] == \"L\").sum())\n",
    "    summary = {\n",
    "        \"n_games\": n_games,\n",
    "        \"display_record_W-L-OTL\": f\"{disp_w}-{disp_rl}-{disp_ol}\",\n",
    "        \"display_points\": int(2 * disp_w + disp_ol),\n",
    "        \"mean_points\": float(sims_totals[\"points\"].mean()),\n",
    "        \"median_points\": float(sims_totals[\"points\"].median()),\n",
    "        \"assumed_otl_share_from_backtest\": round(p_otl, 3),\n",
    "        \"n_sims\": n_sims,\n",
    "        \"mode\": \"simulation_mean_rule\",\n",
    "    }\n",
    "    return display_df, sims_totals, summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted record (W-L-OTL): 41-36-5 | Points: 87\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(         date home_team away_team opponent  home  back_to_back  rest_diff  \\\n",
       " 0  2025-10-08       TOR       MTL      MTL     1             0          0   \n",
       " 1  2025-10-11       DET       TOR      DET     0             0          0   \n",
       " 2  2025-10-13       TOR       DET      DET     1             0          0   \n",
       " 3  2025-10-14       TOR       NSH      NSH     1             1          0   \n",
       " 4  2025-10-16       TOR       NYR      NYR     1             0          0   \n",
       " ..        ...       ...       ...      ...   ...           ...        ...   \n",
       " 77 2026-04-08       TOR       WSH      WSH     1             0          0   \n",
       " 78 2026-04-09       NYI       TOR      NYI     0             1          0   \n",
       " 79 2026-04-11       TOR       FLA      FLA     1             0          0   \n",
       " 80 2026-04-13       TOR       DAL      DAL     1             0          0   \n",
       " 81 2026-04-15       OTT       TOR      OTT     0             0          0   \n",
       " \n",
       "         elo_for  elo_against  win_prob  win_rate display_result  \n",
       " 0   1501.123969  1408.218896     0.560      0.50              W  \n",
       " 1   1501.123969  1442.899590     0.536      0.49              L  \n",
       " 2   1501.123969  1442.899590     0.539      0.45              L  \n",
       " 3   1501.123969  1487.773147     0.505      0.49            OTL  \n",
       " 4   1501.123969  1478.252309     0.517      0.51              W  \n",
       " ..          ...          ...       ...       ...            ...  \n",
       " 77  1501.123969  1549.680981     0.473      0.46              L  \n",
       " 78  1501.123969  1452.205223     0.524      0.50              W  \n",
       " 79  1501.123969  1632.535450     0.423      0.41              L  \n",
       " 80  1501.123969  1532.127545     0.484      0.51              W  \n",
       " 81  1501.123969  1463.979350     0.523      0.40              L  \n",
       " \n",
       " [82 rows x 12 columns],\n",
       "     sim  wins  reg_losses  otl  points record_W-L-OTL\n",
       " 0     0    40          36    6      86        40-36-6\n",
       " 1     1    46          31    5      97        46-31-5\n",
       " 2     2    40          36    6      86        40-36-6\n",
       " 3     3    38          41    3      79        38-41-3\n",
       " 4     4    32          42    8      72        32-42-8\n",
       " ..  ...   ...         ...  ...     ...            ...\n",
       " 95   95    39          37    6      84        39-37-6\n",
       " 96   96    39          36    7      85        39-36-7\n",
       " 97   97    37          38    7      81        37-38-7\n",
       " 98   98    35          40    7      77        35-40-7\n",
       " 99   99    42          37    3      87        42-37-3\n",
       " \n",
       " [100 rows x 6 columns],\n",
       " {'n_games': 82,\n",
       "  'display_record_W-L-OTL': '41-36-5',\n",
       "  'display_points': 87,\n",
       "  'mean_points': 85.96,\n",
       "  'median_points': 86.0,\n",
       "  'assumed_otl_share_from_backtest': 0.133,\n",
       "  'n_sims': 100,\n",
       "  'mode': 'simulation_mean_rule'})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 1) Load schedule (parses DD/MM/YYYY and adds rest features)\n",
    "schedule_df = load_leafs_schedule_from_csv(SCHEDULE_CSV)\n",
    "\n",
    "# 2) Build team Elo map from latest season composites\n",
    "elo_map, _ = build_elo_map(TEAMS_CSV, SAVE_PCT_CSV)\n",
    "\n",
    "# 3) Attach Elo to schedule (Leafs = TOR)\n",
    "sch_with_elos = attach_elo_to_schedule(schedule_df, elo_map, team_abbr=\"TOR\")\n",
    "\n",
    "# 4) Predict with simulations (set n_sims=0 for deterministic)\n",
    "display_df, sims_totals, summary = predict_schedule(\n",
    "    sch_df=sch_with_elos,\n",
    "    backtest_csv=BACKTEST_CSV,\n",
    "    n_sims=100,\n",
    "    rng_seed=7,\n",
    "    use_elo_noise=False\n",
    ")\n",
    "\n",
    "# After: preds_df_or_display_df, sims_totals_or_None, summary = predict_schedule(...)\n",
    "rec = summary.get(\"display_record_W-L-OTL\", summary.get(\"pred_record_W-L-OTL\"))\n",
    "pts = summary.get(\"display_points\", summary.get(\"pred_points\"))\n",
    "print(f\"Predicted record (W-L-OTL): {rec} | Points: {pts}\")\n",
    "\n",
    "\n",
    "# Return the results of the function\n",
    "display_df, sims_totals, summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
